{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callin Switzer\n",
    "April 2019\n",
    "\n",
    "Multiprocessing with multiple arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.7 (default, Feb 28 2019, 07:28:18) [MSC v.1900 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.integrate import odeint\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sys\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import simUtils_twoTorque # note that this is a custom-written file \n",
    "import importlib\n",
    "import functools\n",
    "import sqlite3\n",
    "from collections import OrderedDict\n",
    "\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last run on 2019-11-01 09:38:34.508923\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "print(\"last run on \" + str(now))\n",
    "\n",
    "pythonMadeData = r\"D:/Dropbox/AcademiaDropbox/mothMachineLearning_dataAndFigs/PythonGeneratedData_twoTorque_2\"\n",
    "\n",
    "if not os.path.exists(pythonMadeData):\n",
    "    os.mkdir(pythonMadeData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "_ = importlib.reload(simUtils_twoTorque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save global options\n",
    "\n",
    "globalDict = OrderedDict({\"bhead\": 0.507,\n",
    "            \"ahead\": 0.908,\n",
    "            \"bbutt\": 0.1295,\n",
    "            \"abutt\": 1.7475, \n",
    "            \"rho\": 1, \n",
    "            \"rhoA\": 0.00118, \n",
    "            \"muA\": 0.000186, \n",
    "            \"L1\": 0.908, \n",
    "            \"L2\": 1.7475,  \n",
    "            \"L3\": 0.908,\n",
    "            \"K\": 23000,\n",
    "            \"c\":  14075.8,\n",
    "            \"g\": 980.0,\n",
    "            \"betaR\":  0.0,\n",
    "            \"nstep\": 2,\n",
    "            \"nrun\" : 1000000 # (max) number of  trajectories.\n",
    "            })\n",
    "\n",
    "# Calculated variables\n",
    "globalDict['m1'] = globalDict['rho']*(4/3)*np.pi*(globalDict['bhead']**2)*globalDict['ahead']\n",
    "globalDict[\"m2\"] = globalDict[\"rho\"]*(4/3)*np.pi*(globalDict[\"bbutt\"]**2)*globalDict[\"abutt\"]\n",
    "globalDict[\"echead\"] = globalDict[\"ahead\"]/globalDict[\"bhead\"]\n",
    "globalDict['ecbutt'] = globalDict['abutt']/globalDict['bbutt']\n",
    "globalDict['I1'] = (1/5)*globalDict['m1']*(globalDict['bhead']**2)*(1 + globalDict['echead']**2)\n",
    "globalDict['I2'] = (1/5)*globalDict['m2']*(globalDict['bbutt']**2)*(1 + globalDict['ecbutt']**2)\n",
    "globalDict['S_head'] = np.pi*globalDict['bhead']**2\n",
    "globalDict['S_butt'] = np.pi*globalDict['bbutt'] **2\n",
    "t = np.linspace(0, 0.02, num = globalDict[\"nstep\"], endpoint = True)\n",
    "\n",
    "# convert dict to list, since @jit works better with lists\n",
    "globalList = [ v for v in globalDict.values() ]\n",
    "\n",
    "\n",
    "# ranges for control variables\n",
    "rangeDict = {\"Fmin\": 0,\n",
    "             \"Fmax\": 44300,\n",
    "             \"alphaMin\":  0,\n",
    "             \"alphaMax\":2*np.pi, \n",
    "             \"tau0Min\": -1000000, # refref: this is 10x more than I set for the previous one\n",
    "             \"tau0Max\": 1000000, \n",
    "             \"tau_wMin\": -100000,\n",
    "             \"tau_wMax\": 100000}\n",
    "\n",
    "# ranges for controls \n",
    "ranges = np.array([[rangeDict[\"Fmin\"], rangeDict[\"Fmax\"]], \n",
    "                   [rangeDict[\"alphaMin\"], rangeDict[\"alphaMax\"]], \n",
    "                   [rangeDict[\"tau0Min\"], rangeDict[\"tau0Max\"] ], \n",
    "                   [rangeDict[\"tau_wMin\"], rangeDict[\"tau_wMax\"] ]])\n",
    "\n",
    "# ranges for initial conditions\n",
    "IC_ranges = np.array([[0, 0], \n",
    "                      [-1500, 1500],  \n",
    "                      [0, 0], \n",
    "                      [-1500, 1500],\n",
    "                      [0, 2*np.pi], \n",
    "                      [-25, 25], \n",
    "                      [0, 2*np.pi], \n",
    "                      [-25, 25]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "time for one run: 309.3429124355316\n",
      "1\n",
      "time for one run: 294.9301688671112\n",
      "2\n",
      "time for one run: 301.78392601013184\n",
      "3\n",
      "time for one run: 297.3791446685791\n",
      "4\n",
      "time for one run: 300.8784501552582\n",
      "5\n",
      "time for one run: 293.39779138565063\n",
      "6\n",
      "time for one run: 301.97912764549255\n",
      "7\n",
      "time for one run: 299.20177245140076\n",
      "8\n",
      "time for one run: 317.4520170688629\n",
      "9\n",
      "time for one run: 303.86609506607056\n"
     ]
    }
   ],
   "source": [
    "# start loop here:\n",
    "## refref: I ran this loop twice to generate training data and once for test data\n",
    "\n",
    "dataType = \"trainingData_\"\n",
    "for ii in np.arange(0,10):\n",
    "    print(ii)\n",
    "\n",
    "    # generate random ICs and controls\n",
    "    # random F, alpha, tau, tau_w\n",
    "    FAlphaTau_list = np.random.uniform(ranges[:, 0], ranges[:, 1], \n",
    "                                       size=(globalDict[\"nrun\"], ranges.shape[0]))\n",
    "\n",
    "    # random initial conditions for state 0\n",
    "    state0_ICs = np.random.uniform(IC_ranges[:, 0], IC_ranges[:, 1], size=(globalDict[\"nrun\"], IC_ranges.shape[0]))\n",
    "\n",
    "    # run simulations in parallel, \"nrun\"s at a time\n",
    "    p = Pool(cpu_count() - 1)\n",
    "    stt = time.time()\n",
    "    bb = p.map(functools.partial(simUtils_twoTorque.flyBug_listInput_TwoTorque, t=t, \n",
    "                                  state0_ICs = state0_ICs, \n",
    "                                  FAlphaTau_list= FAlphaTau_list, \n",
    "                                  globalList = globalList), range(globalDict[\"nrun\"]))\n",
    "    print(\"time for one run:\", time.time() - stt)\n",
    "    p.close()\n",
    "    p.join()\n",
    "    \n",
    "    # reshape to put into a pd data frame\n",
    "    bb2 = np.array(bb).reshape(globalDict[\"nrun\"], -1, order = \"F\")\n",
    "    bb3 = np.hstack([bb2, FAlphaTau_list])\n",
    "\n",
    "    simDF = pd.DataFrame(bb3, columns =  [\"x_0\", \"xd_0\",\"y_0\",\"yd_0\",\n",
    "                                         \"theta_0\",\"thetad_0\",\"phi_0\",\"phid_0\", \n",
    "                                         \"x_f\", \"xd_f\",\"y_f\",\"yd_f\",\n",
    "                                         \"theta_f\",\"thetad_f\",\"phi_f\",\"phid_f\", \n",
    "                                              \"F\", \"alpha\", \"tau0\", \"tau_w\"])\n",
    "\n",
    "    # write to database, \n",
    "    # makes a new database if it doesn't already exist\n",
    "    con1 = sqlite3.connect(os.path.join(pythonMadeData, \"twoTorqueData.db\"))\n",
    "\n",
    "\n",
    "    # get table names from database\n",
    "    try:\n",
    "        cursorObj = con1.cursor()\n",
    "        cursorObj.execute('SELECT name from sqlite_master where type= \"table\"')\n",
    "        tableNames = cursorObj.fetchall()\n",
    "        cursorObj.close()\n",
    "    except:\n",
    "        print(\"can't get table names\")\n",
    "\n",
    "    # refref: name changed from \"trainingData_\" to \"testingData_\" when I generated new data\n",
    "    simDF.to_sql(dataType + str(len(tableNames)).zfill(2), con1, if_exists = \"fail\", index = False)\n",
    "    \n",
    "    # close connection\n",
    "    con1.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "time for one run: 297.110356092453\n",
      "1\n",
      "time for one run: 323.5797622203827\n",
      "2\n",
      "time for one run: 298.08820819854736\n",
      "3\n",
      "time for one run: 298.9751365184784\n",
      "4\n",
      "time for one run: 329.3194799423218\n"
     ]
    }
   ],
   "source": [
    "# start loop for test data\n",
    "\n",
    "dataType = \"testingData_\"\n",
    "for ii in np.arange(0,5):\n",
    "    print(ii)\n",
    "\n",
    "    # generate random ICs and controls\n",
    "    # random F, alpha, tau, tau_w\n",
    "    FAlphaTau_list = np.random.uniform(ranges[:, 0], ranges[:, 1], \n",
    "                                       size=(globalDict[\"nrun\"], ranges.shape[0]))\n",
    "\n",
    "    # random initial conditions for state 0\n",
    "    state0_ICs = np.random.uniform(IC_ranges[:, 0], IC_ranges[:, 1], size=(globalDict[\"nrun\"], IC_ranges.shape[0]))\n",
    "\n",
    "    # run simulations in parallel, \"nrun\"s at a time\n",
    "    p = Pool(cpu_count() - 1)\n",
    "    stt = time.time()\n",
    "    bb = p.map(functools.partial(simUtils_twoTorque.flyBug_listInput_TwoTorque, t=t, \n",
    "                                  state0_ICs = state0_ICs, \n",
    "                                  FAlphaTau_list= FAlphaTau_list, \n",
    "                                  globalList = globalList), range(globalDict[\"nrun\"]))\n",
    "    print(\"time for one run:\", time.time() - stt)\n",
    "    p.close()\n",
    "    p.join()\n",
    "    \n",
    "    # reshape to put into a pd data frame\n",
    "    bb2 = np.array(bb).reshape(globalDict[\"nrun\"], -1, order = \"F\")\n",
    "    bb3 = np.hstack([bb2, FAlphaTau_list])\n",
    "\n",
    "    simDF = pd.DataFrame(bb3, columns =  [\"x_0\", \"xd_0\",\"y_0\",\"yd_0\",\n",
    "                                         \"theta_0\",\"thetad_0\",\"phi_0\",\"phid_0\", \n",
    "                                         \"x_f\", \"xd_f\",\"y_f\",\"yd_f\",\n",
    "                                         \"theta_f\",\"thetad_f\",\"phi_f\",\"phid_f\", \n",
    "                                              \"F\", \"alpha\", \"tau0\", \"tau_w\"])\n",
    "\n",
    "    # write to database, \n",
    "    # makes a new database if it doesn't already exist\n",
    "    con1 = sqlite3.connect(os.path.join(pythonMadeData, \"twoTorqueData.db\"))\n",
    "\n",
    "\n",
    "    # get table names from database\n",
    "    try:\n",
    "        cursorObj = con1.cursor()\n",
    "        cursorObj.execute('SELECT name from sqlite_master where type= \"table\"')\n",
    "        tableNames = cursorObj.fetchall()\n",
    "        cursorObj.close()\n",
    "    except:\n",
    "        print(\"can't get table names\")\n",
    "\n",
    "    simDF.to_sql(dataType + str(len(tableNames)).zfill(2), con1, if_exists = \"fail\", index = False)\n",
    "    \n",
    "    # close connection\n",
    "    con1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trainingData_00', 'trainingData_01', 'trainingData_02', 'trainingData_03', 'trainingData_04', 'trainingData_05', 'trainingData_06', 'trainingData_07', 'trainingData_08', 'trainingData_09', 'testingData_10', 'testingData_11', 'testingData_12', 'testingData_13', 'testingData_14']\n"
     ]
    }
   ],
   "source": [
    "# get table names in database\n",
    "con1 = sqlite3.connect(os.path.join(pythonMadeData, \"twoTorqueData.db\"))\n",
    "cursorObj = con1.cursor()\n",
    "res = cursorObj.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tableNames = [name[0] for name in res]\n",
    "con1.close()\n",
    "print(tableNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE test AS SELECT * FROM testingData_10 UNION ALL SELECT * FROM testingData_11 UNION ALL SELECT * FROM testingData_12 UNION ALL SELECT * FROM testingData_13 UNION ALL SELECT * FROM testingData_14\n"
     ]
    }
   ],
   "source": [
    "# Combine testing Data into a single Table\n",
    "con1 = sqlite3.connect(os.path.join(pythonMadeData, \"twoTorqueData.db\"))\n",
    "con1.execute(\"DROP TABLE IF EXISTS test\")\n",
    "sqlStatement = \"CREATE TABLE test AS \" + \" UNION ALL \".join([\"SELECT * FROM \" + tableNames[ii] for ii in range(len(tableNames)) if tableNames[ii].startswith(\"testingData_\")])\n",
    "print(sqlStatement)\n",
    "con1.execute(sqlStatement)\n",
    "con1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE train AS SELECT * FROM trainingData_00 UNION ALL SELECT * FROM trainingData_01 UNION ALL SELECT * FROM trainingData_02 UNION ALL SELECT * FROM trainingData_03 UNION ALL SELECT * FROM trainingData_04 UNION ALL SELECT * FROM trainingData_05 UNION ALL SELECT * FROM trainingData_06 UNION ALL SELECT * FROM trainingData_07 UNION ALL SELECT * FROM trainingData_08 UNION ALL SELECT * FROM trainingData_09\n"
     ]
    }
   ],
   "source": [
    "# Combine Training Data into a single Table\n",
    "con1 = sqlite3.connect(os.path.join(pythonMadeData, \"twoTorqueData.db\"))\n",
    "con1.execute(\"DROP TABLE IF EXISTS train\")\n",
    "sqlStatement = \"CREATE TABLE train AS \" + \" UNION ALL \".join([\"SELECT * FROM \" + tableNames[ii] for ii in range(len(tableNames)) if tableNames[ii].startswith(\"trainingData_\")])\n",
    "print(sqlStatement)\n",
    "con1.execute(sqlStatement)\n",
    "con1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total rows: 10000000\n",
      "\n",
      "Total rows: 5000000\n"
     ]
    }
   ],
   "source": [
    "# print print the max row number\n",
    "def largestRowNumber(cursor, table_name, print_out=False):\n",
    "    \"\"\" Returns the total number of rows in the database \"\"\"\n",
    "    cursor.execute(\"SELECT max(rowid) from  {}\".format(table_name))\n",
    "    n = cursor.fetchone()[0]\n",
    "    if print_out:\n",
    "        print('\\nTotal rows: {}'.format(n))\n",
    "    return(n)\n",
    "\n",
    "con1 = sqlite3.connect(os.path.join(pythonMadeData, \"twoTorqueData.db\"))\n",
    "cursorObj = con1.cursor()\n",
    "largestRowNumber(cursorObj, \"train\", print_out=True)\n",
    "largestRowNumber(cursorObj, \"test\", print_out=True)\n",
    "con1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP TABLE IF EXISTS trainingData_00; DROP TABLE IF EXISTS trainingData_01; DROP TABLE IF EXISTS trainingData_02; DROP TABLE IF EXISTS trainingData_03; DROP TABLE IF EXISTS trainingData_04; DROP TABLE IF EXISTS trainingData_05; DROP TABLE IF EXISTS trainingData_06; DROP TABLE IF EXISTS trainingData_07; DROP TABLE IF EXISTS trainingData_08; DROP TABLE IF EXISTS trainingData_09; \n"
     ]
    }
   ],
   "source": [
    "# drop intermediate, smaller training datasets\n",
    "con1 = sqlite3.connect(os.path.join(pythonMadeData, \"twoTorqueData.db\"))\n",
    "sqlStatement = \"\".join([\"DROP TABLE IF EXISTS \" + tableNames[ii] + \"; \" for ii in range(len(tableNames)) if tableNames[ii].startswith(\"trainingData_\")])\n",
    "print(sqlStatement)\n",
    "con1.executescript(sqlStatement)\n",
    "con1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP TABLE IF EXISTS testingData_10; DROP TABLE IF EXISTS testingData_11; DROP TABLE IF EXISTS testingData_12; DROP TABLE IF EXISTS testingData_13; DROP TABLE IF EXISTS testingData_14; \n"
     ]
    }
   ],
   "source": [
    "# drop intermediate, smaller testing datasets\n",
    "con1 = sqlite3.connect(os.path.join(pythonMadeData, \"twoTorqueData.db\"))\n",
    "sqlStatement = \"\".join([\"DROP TABLE IF EXISTS \" + tableNames[ii] + \"; \" for ii in range(len(tableNames)) if tableNames[ii].startswith(\"testingData_\")])\n",
    "print(sqlStatement)\n",
    "con1.executescript(sqlStatement)\n",
    "con1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train']\n"
     ]
    }
   ],
   "source": [
    "# get table names in database\n",
    "con1 = sqlite3.connect(os.path.join(pythonMadeData, \"twoTorqueData.db\"))\n",
    "cursorObj = con1.cursor()\n",
    "res = cursorObj.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tableNames = [name[0] for name in res]\n",
    "con1.close()\n",
    "print(tableNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check data\n",
    "\n",
    "# con1 = sqlite3.connect(os.path.join(pythonMadeData, \"twoTorqueData.db\"))\n",
    "# trainDF = pd.read_sql_query('''\n",
    "#                             SELECT * FROM train\n",
    "#                             LIMIT 5\n",
    "#                             ''', \n",
    "#                             con1)\n",
    "\n",
    "# con1.close()\n",
    "# trainDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/Dropbox/AcademiaDropbox/mothMachineLearning_dataAndFigs/PythonGeneratedData_twoTorque_2'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pythonMadeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "numSolve_parallel",
   "language": "python",
   "name": "numsolve_parallel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
